#!pip install requests


conda install -c conda-forge fuzzytm



!pip install FuzzyTM


import gensim


#pip install psycopg2
#!pip install xgboost
!!pip install scikit-learn==1.2.2 numpy==1.24.3 --force-reinstall

#!pip install scikit-learn==1.0.2
#!pip install --upgrade imbalanced-learn


import setuptools
import gensim
import sklearn
import numpy

print(f"setuptools version: {setuptools.__version__}")
print(f"gensim version: {gensim.__version__}")
print(f"scikit-learn version: {sklearn.__version__}")
print(f"numpy version: {numpy.__version__}")


import requests
import pandas as pd
from sqlalchemy import create_engine

# Clé API d'AviationStack
api_key = "fcd29088b7d6cbf8974ee006213f27b6"  

# URL de l'API AviationStack pour les informations sur les vols
url = "http://api.aviationstack.com/v1/flights"
# Paramètres pour la requête API
params = {
    'access_key': api_key,
    'limit': 100,   # Nombre de résultats à afficher
    'arr_iata': 'CDG',  # Aéroport d'arrivée (ici Paris Charles de Gaulle)
   
}

# Envoi de la requête GET
response = requests.get(url, params=params)

# Vérification de la réponse
if response.status_code == 200:
    data = response.json()  # Conversion de la réponse en format JSON
    flights_data = data['data']  # Extraire les données des vols
else:
    print(f"Erreur lors de la requête : {response.status_code}")
    flights_data = []


# DataFrame Pandas pour gérer les données
flights_df = pd.DataFrame(flights_data)

# Vérification  si le DataFrame est vide
if flights_df.empty:
    print("Aucune donnée de vol disponible.")
else:
    # Aplatir le DataFrame
    flights_df = pd.DataFrame({
        'flight_date': flights_df['departure'].apply(lambda x: x.get('estimated') if isinstance(x, dict) else None),
        'flight_status': flights_df['flight_status'],
        'airline': flights_df['airline'].apply(lambda x: x.get('name') if isinstance(x, dict) else None),
        'flight': flights_df['flight'].apply(lambda x: x.get('iata') if isinstance(x, dict) else None),
        'aircraft': flights_df['aircraft'].apply(lambda x: x.get('iata') if isinstance(x, dict) else None),
        'live': flights_df['live'],
        'departure_airport': flights_df['departure'].apply(lambda x: x.get('airport') if isinstance(x, dict) else None),
        'departure_time': flights_df['departure'].apply(lambda x: x.get('estimated') if isinstance(x, dict) else None),
        'arrival_airport': flights_df['arrival'].apply(lambda x: x.get('airport') if isinstance(x, dict) else None),
        'arrival_time': flights_df['arrival'].apply(lambda x: x.get('estimated') if isinstance(x, dict) else None),
    })

    # Conversion  explicit toutes les colonnes en type chaîne pour éviter les problèmes de type dict
    for column in flights_df.columns:
        flights_df[column] = flights_df[column].astype(str)
        
# Affichage des types de données et des premières lignes

flights_df







# Connexion à la base de données PostgreSQL
engine = create_engine('postgresql://benothmane:Deguzzy1991%40@localhost:5432/aviation_db')

    # Tentative de sauvegarde du DataFrame dans la table PostgreSQL
try:
        flights_df.to_sql('flights', engine, if_exists='replace', index=False)
        print("Les données ont été sauvegardées dans PostgreSQL.")
except Exception as e:
        print(f"Erreur lors de l'enregistrement dans PostgreSQL : {e}")



#  DataFrame pour voir les données
print("Données de vol récupérées :")
flights_df.head() # Affiche les premières lignes du DataFrame




 # Exportation  des données vers un fichier CSV
output_file_path = "/Users/benothmane/Desktop/AIR_OPTIMISATION/upload/folder/UPDATED_vols.csv"
flights_df.to_csv(output_file_path, index=False)
print(f"Les données ont été exportées vers {output_file_path}.")






import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report
import joblib 
from xgboost import XGBClassifier  # Import de XGBoost
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt
import seaborn as sns

#Importation du dataset 
# Lecture  CSV
df = pd.read_csv('/Users/benothmane/Desktop/AIR_OPTIMISATION/upload/folder/UPDATED_vols.csv')

# Afficher le DataFrame
df



# Import des bibliothèques nécessaires
import numpy as np
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.metrics import classification_report
from imblearn.over_sampling import SMOTE
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
# Nettoyage des données en supprimant les lignes avec des valeurs manquantes
df_cleaned = df.dropna(subset=['flight_status', 'airline', 'flight', 'departure_airport', 'arrival_airport', 'departure_time', 'arrival_time'])

# Conversion des dates
df_cleaned['departure_time'] = pd.to_datetime(df_cleaned['departure_time'])
df_cleaned['arrival_time'] = pd.to_datetime(df_cleaned['arrival_time'])

# Vérification de la distribution des classes dans 'flight_status'
print("Répartition des statuts de vol:")
print(df_cleaned['flight_status'].value_counts())

# Création de la variable cible 'needs_parking' (1 si 'landed', sinon 0)
df_cleaned['needs_parking'] = np.where(
    (df_cleaned['flight_status'] == 'landed') |
    ((df_cleaned['flight_status'] == 'active') & (df_cleaned['arrival_time'] - df_cleaned['departure_time']).dt.seconds > 600), 
    1, 0
)

# Extraction des heures de départ et d'arrivée
df_cleaned['departure_hour'] = df_cleaned['departure_time'].dt.hour
df_cleaned['arrival_hour'] = df_cleaned['arrival_time'].dt.hour

# Sélection des caractéristiques pour l'entraînement
X = df_cleaned[['flight', 'flight_status', 'airline', 'departure_hour', 'arrival_hour', 'departure_airport', 'arrival_airport']]
y = df_cleaned['needs_parking']

# Encodage des variables catégorielles avec .loc pour éviter l'avertissement SettingWithCopyWarning
label_encoders = {}
for column in ['flight_status', 'airline', 'departure_airport', 'arrival_airport']:
    le = LabelEncoder()
    X.loc[:, column] = le.fit_transform(X[column])
    label_encoders[column] = le

# Encodage de la colonne "flight"
X.loc[:, 'flight'] = X['flight'].astype('category').cat.codes

# Vérification de la répartition des classes dans 'needs_parking'
print("Répartition des classes dans 'needs_parking':")
print(y.value_counts())

# Séparation des données en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=42)

# Appliquer SMOTE pour rééquilibrer les classes
smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)

# Calcul du poids de la classe pour rééquilibrer l'importance des classes
scale_pos_weight = len(y_train) / (2 * sum(y_train == 1))  # ajuster selon la proportion des classes
print(f"Poids de la classe minoritaire (scale_pos_weight): {scale_pos_weight}")

# Entraînement du modèle XGBoost avec des données rééquilibrées
model = XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss', scale_pos_weight=scale_pos_weight)
model.fit(X_train_res, y_train_res)

# Sauvegarde du modèle
MODEL_PATH = '/Users/benothmane/Desktop/AIR_OPTIMISATION/models/TRAIN_model_xgboost.pkl'
joblib.dump(model, MODEL_PATH)
print(f"Modèle sauvegardé avec succès à l'emplacement : {MODEL_PATH}")

# Prédictions sur l'ensemble de test
y_pred = model.predict(X_test)

# Rapport de classification pour évaluer les performances
classification_rep = classification_report(y_test, y_pred, zero_division=1)
print("Rapport de classification :\n", classification_rep)

# Vérification des valeurs uniques prédites
predicted_unique_values = np.unique(y_pred)
print("Valeurs uniques prédites : ", predicted_unique_values)

# Affichage des résultats des prédictions sur l'ensemble de test
results = X_test.copy()
results['needs_parking'] = y_pred

# Décodage des variables catégorielles pour les résultats
results['airline'] = label_encoders['airline'].inverse_transform(results['airline'].astype(int))
results['flight_status'] = label_encoders['flight_status'].inverse_transform(results['flight_status'].astype(int))
results['departure_airport'] = label_encoders['departure_airport'].inverse_transform(results['departure_airport'].astype(int))
results['arrival_airport'] = label_encoders['arrival_airport'].inverse_transform(results['arrival_airport'].astype(int))

# Résultats des prédictions 
for index, row in results.iterrows():
    if row['needs_parking'] == 1:
        print(f"L'Avion de {row['airline']} (ID: {row['flight']}) nécessite un stationnement.")
    else:
        print(f"L'Avion de {row['airline']} (ID: {row['flight']}) ne nécessite pas de stationnement.")

# Visualisation de l'importance des caractéristiques
feature_importances = model.feature_importances_
features = X.columns

plt.figure(figsize=(10, 6))
sns.barplot(x=feature_importances, y=features)
plt.title("Importance des caractéristiques")
plt.show()


 


# Préparation des  données pour le DataFrame des résultats
predictions_data = []

# Listing des resultats
for index, row in results.iterrows():
    predictions_data.append({
        "Airline": row['airline'],
        "Flight ID": row['flight'],
        "Needs Parking": " nécessite un stationnement" if row['needs_parking'] == 1 else "ne nécessite pas de stationnement."
    })

# DataFrame des résultats
predictions_df = pd.DataFrame(predictions_data)

predictions_df # Afficher les premières lignes pour vérification



# Comptage du nombre d'avions nécessitant un stationnement ou non
parking_counts = results['needs_parking'].value_counts()



plt.figure(figsize=(10, 6))
plt.bar(['Ne nécessite pas de stationnement', 'Nécessite un stationnement'], parking_counts, color=['blue', 'green'])
plt.title("Nombre d'avions nécessitant un stationnement ou non")
plt.xlabel("Stationnement")
plt.ylabel("Nombre d'avions")
plt.show()


# Comptage du nombre d'avions nécessitant un stationnement ou non
parking_counts = results['needs_parking'].value_counts()

# Diagramme en camembert pour visualiser les résultats
plt.figure(figsize=(8, 8))
plt.pie(parking_counts, labels=['Ne nécessite pas de stationnement', 'Nécessite un stationnement'], 
        autopct='%1.1f%%', colors=['blue', 'green'], startangle=140)
plt.title("Répartition des avions nécessitant un stationnement ou non")
plt.show()


# Stockage des résultats
predictions_data = []

# Parcours des résultats pour les ajouter à la liste
for index, row in results.iterrows():
    predictions_data.append({
        "Airline": row['airline'],
        "Flight ID": row['flight'],
        "Needs Parking": "nécessite un stationnement" if row['needs_parking'] == 1 else "ne nécessite pas de stationnement."
    })

# DataFrame des résultats
predictions_df = pd.DataFrame(predictions_data)

# Sauvegarder le DataFrame de prédiction dans un fichier CSV
output_file_path = '/Users/benothmane/Desktop/flight_dashboard/upload/folder/VOL_pred2.csv'
predictions_df.to_csv(output_file_path, index=False, sep='\t')  # Utiliser un séparateur tabulaire

print(f"DataFrame sauvegardé dans {output_file_path}")






import pandas as pd
from sklearn.metrics import classification_report

# Affichage des résultats des prédictions sur l'ensemble de test
results = X_test.copy()
results['needs_parking'] = y_pred

# Décodage des variables catégorielles pour les résultats
results['airline'] = label_encoders['airline'].inverse_transform(results['airline'].astype(int))
results['flight_status'] = label_encoders['flight_status'].inverse_transform(results['flight_status'].astype(int))
results['departure_airport'] = label_encoders['departure_airport'].inverse_transform(results['departure_airport'].astype(int))
results['arrival_airport'] = label_encoders['arrival_airport'].inverse_transform(results['arrival_airport'].astype(int))

# Vérification de la correspondance des longueurs
if len(results) != len(y_pred):
    print("Erreur: La longueur de results et y_pred ne correspond pas.")
else:
    # Rapport de classification pour évaluer les performances
    classification_rep = classification_report(y_test, y_pred)
    print("Rapport de classification :\n", classification_rep)

    # Vérification des valeurs uniques prédites
    predicted_unique_values = np.unique(y_pred)
    print("Valeurs uniques prédites : ", predicted_unique_values)

    # Optimisation des résultats
    optimized_results = []
    for index, row in results.iterrows():
        # Créer un dictionnaire pour chaque vol
        result_entry = {
            "Airline": row['airline'],
            "Flight ID": row['flight'],
            "Needs Parking": None
        }

        print(f"Analyse du vol : {row['flight']} de la compagnie {row['airline']}")

        if row['needs_parking'] == 1:
            print(f"L'Avion de {row['airline']} (ID: {row['flight']}) peut stationner sur le tarmac ,espace libre" )
            result_entry["Needs Parking"] = "peut stationner"
        else:
            print(f"L'Avion de {row['airline']} (ID: {row['flight']})  ne peut pas stationner sur le tarmac !!!!")
            # Logique d'optimisation supplémentaire pour les heures de pointe
            if row['arrival_hour'] in [7, 8, 17, 18]:  # Heures de pointe
                print("Attention : l'atterrissage aura  eu lieu pendant les heures de pointe, le stationnement pourrait être compliqué!!!!!!")
                result_entry["Needs Parking"] = "Atterrissage pendant les heures de pointe, réaménagement immédiat!!!!!!!!!"
            else:
                result_entry["Needs Parking"] = "Ne peut pas stationner!!!!!!"

        optimized_results.append(result_entry)

    # Création d'un DataFrame à partir des résultats optimisés
    df_optimized_results = pd.DataFrame(optimized_results)
    df_optimized_results


import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns


df_optimized_results = pd.DataFrame(data)

# Compter le nombre de vols selon les besoins de stationnement
parking_counts = df_optimized_results['Needs Parking'].value_counts()

# Histogramme (Bar Chart)
plt.figure(figsize=(10, 6))
sns.barplot(x=parking_counts.index, y=parking_counts.values, hue=parking_counts.index, palette="viridis", dodge=False)
plt.title('Nombre de Vols selon les Besoins de Stationnement')
plt.xlabel('Besoins de Stationnement')
plt.ylabel('Nombre de Vols')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Camembert (Pie Chart)
plt.figure(figsize=(8, 8))
plt.pie(parking_counts, labels=parking_counts.index, autopct='%1.1f%%', startangle=140, colors=sns.color_palette("pastel"))
plt.title('Répartition des Besoins de Stationnement')
plt.axis('equal')  # Pour que le camembert soit un cercle
plt.show()






# Cellule 1: Demander à l'utilisateur de saisir le chemin du fichier CSV
csv_file_path = input("Veuillez entrer le chemin du fichier CSV : ")

# Cellule 2: Charger les données du fichier CSV
df = pd.read_csv(csv_file_path)

# Cellule 3: Demander à l'utilisateur de saisir le chemin du modèle préalablement sauvegardé
model_path = input("Veuillez entrer le chemin du modèle (fichier .pkl) : ")
model = joblib.load(model_path)  # Charger le modèle

# Cellule 4: Préparation des données pour la prédiction
df_cleaned = df.dropna(subset=['flight_status', 'airline', 'departure_airport', 'arrival_airport', 'departure_time', 'arrival_time'])
df_cleaned['departure_time'] = pd.to_datetime(df_cleaned['departure_time'])
df_cleaned['arrival_time'] = pd.to_datetime(df_cleaned['arrival_time'])
df_cleaned['departure_hour'] = df_cleaned['departure_time'].dt.hour
df_cleaned['arrival_hour'] = df_cleaned['arrival_time'].dt.hour

# Sélection et encodage des caractéristiques
X = df_cleaned[['flight', 'flight_status', 'airline', 'departure_hour', 'arrival_hour', 'departure_airport', 'arrival_airport']].copy()  # Utilisation de .copy()
for column in ['flight_status', 'airline', 'departure_airport', 'arrival_airport']:
    le = LabelEncoder()
    X[column] = le.fit_transform(X[column])

X['flight'] = X['flight'].astype('category').cat.codes  # Pas de SettingWithCopyWarning

# Cellule 5: Prédictions sur les données
y_pred = model.predict(X)

# Ajouter les résultats de prédiction au DataFrame
df_cleaned['needs_parking'] = y_pred

# Cellule 6: Créer un DataFrame pour les résultats
results_df = df_cleaned[['flight', 'airline', 'flight_status', 'needs_parking']].copy()
results_df['needs_parking'] = results_df['needs_parking'].map({1: 'Nécessite un stationnement', 0: 'Ne nécessite pas de stationnement'})

# Affichage du DataFrame des résultats
results_df


import pickle
# Charger le modèle
model_path = "/Users/benothmane/Desktop/flight_dashboard/models/new_models.pkl"
try:
    with open(model_path, "rb") as model_file:
        model = pickle.load(model_file)
        if not hasattr(model, "predict"):
            raise ValueError("Le modèle chargé n'est pas valide.")
except Exception as e:
    print(f"Erreur lors du chargement du modèle : {e}")


import os

model_path = "/Users/benothmane/Desktop/flight_dashboard/models/new_models.pkl"
if not os.path.exists(model_path):
    print("Le fichier du modèle n'existe pas.")
else:
    print("Le fichier du modèle existe.")


# Vérifiez le contenu du fichier du modèle
with open(model_path, "rb") as model_file:
    content = model_file.read(20)  # Lire les 20 premiers octets
    print(content)


import sklearn
print(sklearn.__version__)


import pandas as pd
from sklearn.ensemble import RandomForestClassifier
import pickle

# Créer un jeu de données d'exemple
data = {
    'feature1': [1, 2, 3, 4, 5],
    'feature2': [5, 4, 3, 2, 1],
    'target': [0, 1, 0, 1, 0]
}
df = pd.DataFrame(data)

# Séparer les caractéristiques et la cible
X = df[['feature1', 'feature2']]
y = df['target']

# Entraîner le modèle
model = RandomForestClassifier()
model.fit(X, y)

# Sauvegarder le modèle
model_path = "/Users/benothmane/Desktop/flight_dashboard/models/new_models.pkl"
with open(model_path, "wb") as model_file:
    pickle.dump(model, model_file)

print("Modèle réentraîné et sauvegardé avec succès.")




